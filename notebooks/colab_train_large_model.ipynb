{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843d2316",
   "metadata": {},
   "source": [
    "# üöÄ Train Large Model - VS Code Version\n",
    "\n",
    "This notebook trains ONLY the large/bestfit model.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Make sure dataset is at: `dataset/Pride_and_Prejudice-Jane_Austen.txt`\n",
    "2. Run all cells\n",
    "3. Results will be saved to `models/` and `results/` folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9e9a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n",
      "‚úÖ Using existing environment\n"
     ]
    }
   ],
   "source": [
    "# Check dependencies (already installed in your environment)\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"‚úÖ Using existing environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b0d53",
   "metadata": {},
   "source": [
    "## üìÅ Step 2: Set Dataset Path\n",
    "\n",
    "Using dataset from your project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944fe2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found dataset: ../dataset/Pride_and_Prejudice-Jane_Austen.txt\n",
      "   Size: 694.67 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set dataset path (relative to notebook location)\n",
    "dataset_filename = '../dataset/Pride_and_Prejudice-Jane_Austen.txt'\n",
    "\n",
    "# Verify file exists\n",
    "if os.path.exists(dataset_filename):\n",
    "    print(f\"‚úÖ Found dataset: {dataset_filename}\")\n",
    "    print(f\"   Size: {os.path.getsize(dataset_filename) / 1024:.2f} KB\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found at: {dataset_filename}\")\n",
    "    print(\"   Please check the path!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817803c7",
   "metadata": {},
   "source": [
    "## üîß Step 3: Setup Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77508a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Directory structure created\n"
     ]
    }
   ],
   "source": [
    "# Create directories (relative to notebook location)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../vocab', exist_ok=True)\n",
    "os.makedirs('../results/plots', exist_ok=True)\n",
    "os.makedirs('../results/metrics', exist_ok=True)\n",
    "os.makedirs('../results/logs', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbb218",
   "metadata": {},
   "source": [
    "## üíª Step 4: Define Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05975f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded - BESTFIT MODEL\n",
      "   Model: LARGE (Balanced)\n",
      "   Embedding: 200, Hidden: 400, Layers: 2\n",
      "   This is between SMALL (128/256/1) and MEDIUM (256/512/2)\n",
      "   Uses SAME vocab as your trained models ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "def get_config(model_type='large'):\n",
    "    \"\"\"Get configuration for large model - BESTFIT (balanced size)\"\"\"\n",
    "    return {\n",
    "        'data_path': dataset_filename,\n",
    "        'vocab_path': '../vocab/vocab.pkl',\n",
    "        'model_save_dir': '../models/',\n",
    "        'results_dir': '../results/',\n",
    "        \n",
    "        # Data parameters\n",
    "        'seq_length': 35,\n",
    "        'min_freq': 2,\n",
    "        'batch_size': 64,\n",
    "        'train_ratio': 0.8,\n",
    "        'val_ratio': 0.1,\n",
    "        'num_workers': 0,  # VS Code/Windows compatibility\n",
    "        \n",
    "        # Training parameters\n",
    "        'num_epochs': 20,\n",
    "        'learning_rate': 0.001,\n",
    "        'grad_clip': 5.0,\n",
    "        'patience': 5,\n",
    "        'save_every': 5,\n",
    "        \n",
    "        # Large model architecture (Balanced between small and medium)\n",
    "        'embedding_dim': 200,  # Between small (128) and medium (256)\n",
    "        'hidden_dim': 400,     # Between small (256) and medium (512)\n",
    "        'num_layers': 2,       # Between small (1) and medium (2)\n",
    "        'dropout': 0.4,        # Between small (0.3) and medium (0.4)\n",
    "        'model_type': model_type,\n",
    "        \n",
    "        # Generation parameters\n",
    "        'gen_length': 50,\n",
    "        'temperature': 1.0,\n",
    "    }\n",
    "\n",
    "config = get_config('large')\n",
    "print(\"‚úÖ Configuration loaded - BESTFIT MODEL\")\n",
    "print(f\"   Model: {config['model_type'].upper()} (Balanced)\")\n",
    "print(f\"   Embedding: {config['embedding_dim']}, Hidden: {config['hidden_dim']}, Layers: {config['num_layers']}\")\n",
    "print(f\"   This is between SMALL (128/256/1) and MEDIUM (256/512/2)\")\n",
    "print(f\"   Uses SAME vocab as your trained models ‚úÖ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fefd032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vocabulary class defined\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# Vocabulary class\n",
    "class Vocabulary:\n",
    "    def __init__(self, min_freq=2):\n",
    "        self.min_freq = min_freq\n",
    "        self.word2idx = {'<pad>': 0, '<unk>': 1}\n",
    "        self.idx2word = {0: '<pad>', 1: '<unk>'}\n",
    "        self.word_freq = Counter()\n",
    "    \n",
    "    def build_vocab(self, texts):\n",
    "        for text in texts:\n",
    "            self.word_freq.update(text.split())\n",
    "        \n",
    "        idx = 2\n",
    "        for word, freq in self.word_freq.items():\n",
    "            if freq >= self.min_freq:\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "                idx += 1\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        return [self.word2idx.get(word, 1) for word in text.split()]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        return ' '.join([self.idx2word.get(idx, '<unk>') for idx in indices])\n",
    "\n",
    "print(\"‚úÖ Vocabulary class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba57bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset class defined\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, vocab, seq_length):\n",
    "        self.vocab = vocab\n",
    "        self.seq_length = seq_length\n",
    "        self.encoded_text = vocab.encode(text)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.encoded_text) - self.seq_length)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.encoded_text[idx:idx + self.seq_length]\n",
    "        y = self.encoded_text[idx + 1:idx + self.seq_length + 1]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "print(\"‚úÖ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40d7f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LSTM Model class defined\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout=0.5):\n",
    "        super(LSTMLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.dropout(output)\n",
    "        logits = self.fc(output)\n",
    "        return logits, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "print(\"‚úÖ LSTM Model class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7df0a6",
   "metadata": {},
   "source": [
    "## üìö Step 5: Prepare Dataset & Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa8dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded EXISTING vocabulary (same as small/medium models)\n",
      "   Vocab size: 6250\n",
      "   Total words in dataset: 124970\n",
      "‚úÖ Datasets created (using SAME split as small/medium)\n",
      "   Train: 100000 sequences\n",
      "   Val: 12655 sequences\n",
      "   Test: 12211 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare text\n",
    "with open(dataset_filename, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Load EXISTING vocabulary (same as small/medium models)\n",
    "vocab_path = config['vocab_path']\n",
    "if os.path.exists(vocab_path):\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded EXISTING vocabulary (same as small/medium models)\")\n",
    "    print(f\"   Vocab size: {len(vocab)}\")\n",
    "else:\n",
    "    # Only build if doesn't exist\n",
    "    vocab = Vocabulary(min_freq=config['min_freq'])\n",
    "    vocab.build_vocab([text])\n",
    "    with open(vocab_path, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "    print(f\"‚úÖ Built NEW vocabulary\")\n",
    "    print(f\"   Vocab size: {len(vocab)}\")\n",
    "\n",
    "print(f\"   Total words in dataset: {len(text.split())}\")\n",
    "\n",
    "# Split data (SAME split as small/medium models)\n",
    "train_size = int(config['train_ratio'] * len(text))\n",
    "val_size = int(config['val_ratio'] * len(text))\n",
    "\n",
    "train_text = text[:train_size]\n",
    "val_text = text[train_size:train_size + val_size]\n",
    "test_text = text[train_size + val_size:]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TextDataset(train_text, vocab, config['seq_length'])\n",
    "val_dataset = TextDataset(val_text, vocab, config['seq_length'])\n",
    "test_dataset = TextDataset(test_text, vocab, config['seq_length'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], \n",
    "                         shuffle=True, num_workers=config['num_workers'])\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], \n",
    "                       shuffle=False, num_workers=config['num_workers'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], \n",
    "                        shuffle=False, num_workers=config['num_workers'])\n",
    "\n",
    "print(f\"‚úÖ Datasets created (using SAME split as small/medium)\")\n",
    "print(f\"   Train: {len(train_dataset)} sequences\")\n",
    "print(f\"   Val: {len(val_dataset)} sequences\")\n",
    "print(f\"   Test: {len(test_dataset)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b7049",
   "metadata": {},
   "source": [
    "## üéØ Step 6: Initialize Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7273eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Using device: cuda\n",
      "   GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   Memory: 4.29 GB\n",
      "\n",
      "‚úÖ Model initialized\n",
      "   Total parameters: 6,002,650\n",
      "   Trainable parameters: 6,002,650\n",
      "\n",
      "‚úÖ Model initialized\n",
      "   Total parameters: 6,002,650\n",
      "   Trainable parameters: 6,002,650\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Create model\n",
    "model = LSTMLanguageModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    hidden_dim=config['hidden_dim'],\n",
    "    num_layers=config['num_layers'],\n",
    "    dropout=config['dropout']\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model initialized\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af4318",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Train Large Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f86ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, grad_clip):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc='Training', leave=False) as pbar:\n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    return avg_loss, perplexity\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ TRAINING LARGE MODEL\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20 | Train Loss: 5.4043 | Val Loss: 5.3586 | Val PPL: 212.42 | Time: 56.7s\n",
      "   ‚≠ê Best model saved! (Val Loss: 5.3586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/20 | Train Loss: 4.2693 | Val Loss: 5.5080 | Val PPL: 246.65 | Time: 56.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/20 | Train Loss: 3.7583 | Val Loss: 5.7679 | Val PPL: 319.86 | Time: 56.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1095/1563 [00:38<00:16, 28.74it/s, loss=3.3162]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ TRAINING LARGE MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_perplexities = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, config['num_epochs'] + 1):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, config['grad_clip'])\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_perplexity = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_perplexities.append(val_perplexity)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d}/{config['num_epochs']} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | \"\n",
    "          f\"Val PPL: {val_perplexity:.2f} | \"\n",
    "          f\"Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if epoch % config['save_every'] == 0:\n",
    "        checkpoint_path = os.path.join(config['model_save_dir'], f\"large_epoch_{epoch}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_perplexity': val_perplexity,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"   üíæ Checkpoint saved: large_epoch_{epoch}.pt\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        \n",
    "        best_model_path = os.path.join(config['model_save_dir'], \"large_model_best.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_perplexity': val_perplexity,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_perplexities': val_perplexities,\n",
    "            'config': config,\n",
    "        }, best_model_path)\n",
    "        print(f\"   ‚≠ê Best model saved! (Val Loss: {val_loss:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"\\n‚ö†Ô∏è  Early stopping triggered (patience={config['patience']})\")\n",
    "            break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Training complete! Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Best validation perplexity: {math.exp(best_val_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af4e19",
   "metadata": {},
   "source": [
    "## üìä Step 8: Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(train_losses, label='Train Loss', marker='o')\n",
    "axes[0].plot(val_losses, label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss - Large Model')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Perplexity plot\n",
    "axes[1].plot(val_perplexities, label='Val Perplexity', marker='s', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Perplexity')\n",
    "axes[1].set_title('Validation Perplexity - Large Model')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = 'results/plots/large_model_training.png'\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Plot saved: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3f139",
   "metadata": {},
   "source": [
    "## üß™ Step 9: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_perplexity = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1ce48",
   "metadata": {},
   "source": [
    "## üìù Step 10: Generate Text Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5357b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, vocab, seed_text, length=50, temperature=1.0, device='cpu'):\n",
    "    \"\"\"Generate text from seed text\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    tokens = seed_text.split()\n",
    "    input_seq = torch.tensor([vocab.word2idx.get(w, 1) for w in tokens]).unsqueeze(0).to(device)\n",
    "    \n",
    "    generated = tokens.copy()\n",
    "    hidden = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            logits = output[0, -1] / temperature\n",
    "            probs = torch.softmax(logits, dim=0)\n",
    "            next_token = torch.multinomial(probs, 1).item()\n",
    "            \n",
    "            next_word = vocab.idx2word.get(next_token, '<unk>')\n",
    "            generated.append(next_word)\n",
    "            \n",
    "            input_seq = torch.tensor([[next_token]]).to(device)\n",
    "    \n",
    "    return ' '.join(generated)\n",
    "\n",
    "# Generate samples\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù GENERATED TEXT SAMPLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "seed_texts = [\n",
    "    \"It is a truth universally acknowledged that\",\n",
    "    \"Mr. Darcy was\",\n",
    "    \"Elizabeth felt\"\n",
    "]\n",
    "\n",
    "generated_samples = []\n",
    "for i, seed in enumerate(seed_texts, 1):\n",
    "    generated = generate_text(model, vocab, seed, length=config['gen_length'], \n",
    "                             temperature=config['temperature'], device=device)\n",
    "    generated_samples.append(generated)\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Seed: '{seed}'\")\n",
    "    print(f\"Generated: {generated}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8251fbe",
   "metadata": {},
   "source": [
    "## üíæ Step 11: Save Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7982b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'model_type': 'large',\n",
    "    'total_epochs': len(train_losses),\n",
    "    'best_epoch': checkpoint['epoch'],\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_val_perplexity': math.exp(best_val_loss),\n",
    "    'test_loss': test_loss,\n",
    "    'test_perplexity': test_perplexity,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'val_perplexities': val_perplexities,\n",
    "    'training_time_minutes': total_time / 60,\n",
    "    'total_parameters': total_params,\n",
    "    'config': config,\n",
    "}\n",
    "\n",
    "metrics_path = 'results/metrics/large_model_metrics.json'\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Metrics saved: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898b3bf",
   "metadata": {},
   "source": [
    "## üì• Step 12: Results Saved\n",
    "\n",
    "All results are saved to your project folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e15f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved files\n",
    "print(\"üì¶ Saved files:\\n\")\n",
    "\n",
    "print(\"Checkpoints:\")\n",
    "checkpoint_files = [f for f in os.listdir('../models/') if f.startswith('large_')]\n",
    "for i, ckpt in enumerate(checkpoint_files, 1):\n",
    "    print(f\"  {i}. models/{ckpt}\")\n",
    "\n",
    "print(\"\\nVocabulary:\")\n",
    "print(f\"  ‚Ä¢ vocab/vocab.pkl\")\n",
    "\n",
    "print(\"\\nPlots:\")\n",
    "if os.path.exists('../results/plots/large_model_training.png'):\n",
    "    print(f\"  ‚Ä¢ results/plots/large_model_training.png\")\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "if os.path.exists('../results/metrics/large_model_metrics.json'):\n",
    "    print(f\"  ‚Ä¢ results/metrics/large_model_metrics.json\")\n",
    "\n",
    "print(\"\\n‚úÖ All files saved in your project folders!\")\n",
    "print(f\"   Total checkpoints: {len(checkpoint_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6301317",
   "metadata": {},
   "source": [
    "## üìä Step 13: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìà Model Performance:\")\n",
    "print(f\"   ‚Ä¢ Model Type: LARGE (bestfit)\")\n",
    "print(f\"   ‚Ä¢ Architecture: {config['embedding_dim']}‚Üí{config['hidden_dim']}√ó{config['num_layers']} layers\")\n",
    "print(f\"   ‚Ä¢ Total Parameters: {total_params:,}\")\n",
    "print(f\"   ‚Ä¢ Training Time: {total_time/60:.1f} minutes\")\n",
    "print(f\"   ‚Ä¢ Epochs Trained: {len(train_losses)}/{config['num_epochs']}\")\n",
    "print(f\"\\nüéØ Best Results:\")\n",
    "print(f\"   ‚Ä¢ Best Epoch: {checkpoint['epoch']}\")\n",
    "print(f\"   ‚Ä¢ Best Val Loss: {best_val_loss:.4f}\")\n",
    "print(f\"   ‚Ä¢ Best Val Perplexity: {math.exp(best_val_loss):.2f}\")\n",
    "print(f\"\\nüß™ Test Performance:\")\n",
    "print(f\"   ‚Ä¢ Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   ‚Ä¢ Test Perplexity: {test_perplexity:.2f}\")\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(f\"   ‚Ä¢ Model: large_model_best.pt\")\n",
    "print(f\"   ‚Ä¢ Vocabulary: vocab.pkl\")\n",
    "print(f\"   ‚Ä¢ Plot: large_model_training.png\")\n",
    "print(f\"   ‚Ä¢ Metrics: large_model_metrics.json\")\n",
    "print(f\"   ‚Ä¢ Checkpoints: {len(checkpoint_files)} files\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Upload these files to your local project's models/ and vocab/ folders\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
